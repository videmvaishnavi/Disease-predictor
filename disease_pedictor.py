# -*- coding: utf-8 -*-
"""Disease pedictor.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17uXIqa_VbvAQxpA5uOnp1AJeIBUYoyXv
"""

from google.colab import files
files.upload()

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!pip install kaggle

!kaggle datasets download -d redwankarimsony/heart-disease-data -p /content/heart-disease --unzip

import pandas as pd
df = pd.read_csv('/content/heart-disease/heart_disease_uci.csv')

df.head()

print(df.columns)

df.isnull().sum()

numeric_cols = df.select_dtypes(include='number').columns
df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].mean())

import matplotlib.pyplot as plt
import seaborn as sns

df[numeric_cols].hist(figsize=(15,10))
plt.tight_layout()
plt.show()

sns.heatmap(df[numeric_cols].corr(), annot=True, cmap='coolwarm')
plt.title('Numeric Feature Corelations')
plt.show()

cat_cols = df.select_dtypes(include='object').columns.tolist()
if 'num' in cat_cols:
  cat_cols.remove('num')

X = df.drop('num', axis=1)
y = (df['num'] > 0).astype(int)

X = pd.get_dummies(X, columns=cat_cols)
print("Final feature columns:", X.columns)

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""new value = (x-mean)/standard deviation"""

scalar = StandardScaler()
X_train_scaled = scalar.fit_transform(X_train)
X_test_scaled = scalar.transform(X_test)

from sklearn.linear_model import LogisticRegression    #its about classification

lr_model = LogisticRegression()                #giving admission to new student
lr_model.fit(X_train_scaled, y_train)            #training step

"""Model Evaluation

"""

from sklearn.metrics import accuracy_score

from sklearn.metrics import classification_report, accuracy_score

y_pred_lr = lr_model.predict(X_test_scaled)
print("Logistic Regression Accuracy:", accuracy_score(y_test, y_pred_lr))
print(classification_report(y_test, y_pred_lr))

"""Accuracy Score - 75 to 98 considered to be good"""

from sklearn.metrics import confusion_matrix

cm = confusion_matrix(y_test, y_pred_lr)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix (Logistic Regression)')
plt.show()

"""Random Forest"""

from sklearn.ensemble import RandomForestClassifier

rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train_scaled, y_train)
y_pred_rf = rf_model.predict(X_test_scaled)

print("Random Forest Accuracy:", accuracy_score(y_test, y_pred_rf))

"""Feature Importance"""

feat_imp = pd.Series(rf_model.feature_importances_, index=X.columns)
feat_imp.nlargest(10).plot(kind='barh')
plt.title('Top 10 Feature Importances')
plt.show()

"""Save the model"""

import joblib
joblib.dump(rf_model, 'heart_rf_model.pkl')

joblib.dump(scalar, 'heart_scaler.pkl')

sample = X.head(1)
sample.to_csv('Heart_user_template.csv', index=False)
print("User Template saved as 'Heart_user_template.csv' ")

from google.colab import files
files.upload()

import joblib
import pandas as pd

user_df = pd.read_csv('heart_dataset.csv')

# Get column lists from training dataframe
numeric_cols = df.select_dtypes(include='number').columns.tolist()
cat_cols = df.select_dtypes(include='object').columns.tolist()
bool_cols = df.select_dtypes(include='bool').columns.tolist()

# Drop columns not in user_df to avoid errors
numeric_cols = [col for col in numeric_cols if col in user_df.columns]
cat_cols = [col for col in cat_cols if col in user_df.columns]
bool_cols = [col for col in bool_cols if col in user_df.columns]

# Fill missing values in numeric columns with training set mean
user_df[numeric_cols] = user_df[numeric_cols].fillna(df[numeric_cols].mean())

# Fill missing values in categorical columns with 'Unknown'
for col in cat_cols:
    user_df[col] = user_df[col].fillna('Unknown')

# Convert boolean columns to int
for col in bool_cols:
    user_df[col] = user_df[col].astype(int)

# One-hot encode categorical columns
user_df_encoded = pd.get_dummies(user_df, columns=cat_cols)

# Align columns with training features X.columns
user_df_encoded = user_df_encoded.reindex(columns=X.columns, fill_value=0)

# Scale data
scaler = joblib.load('heart_scaler.pkl')
user_scaled = scaler.transform(user_df_encoded)

# Predict
model = joblib.load('heart_rf_model.pkl')
preds = model.predict(user_scaled)
user_df['Heart_Disease_Prediction'] = preds

print(user_df)

